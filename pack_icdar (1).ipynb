{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cambrian import Dataset\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "img_102.jpg\n",
      "Shop\n",
      "Dine\n",
      "SMRT\n",
      "validate\n",
      "img_102.jpg\n",
      "ST.MARC\n",
      "CAFE\n",
      "###\n",
      "###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "width = 720\n",
    "height = 1280\n",
    "dt = h5py.special_dtype(vlen=str)\n",
    "h5 = h5py.File('test2.h5', 'w')\n",
    "dataset = ['train', 'validate']\n",
    "\n",
    "train_num = len(os.listdir('train_gts'))\n",
    "validate_num = len(os.listdir('test_gts'))\n",
    "# train_num = 1\n",
    "# validate_num = 1\n",
    "\n",
    "h5.create_dataset(\"meta-dataset\", (1,), h5py.special_dtype(vlen=str))\n",
    "meta_dataset = {'general': {'image_count': {'train': train_num, 'validate': validate_num, 'test': 0}, \n",
    "                            'labeled_image_count': train_num + validate_num, \n",
    "                            'unlabeled_image_count': 0, \n",
    "                            'image_dataset_format': \"Binary\", \n",
    "                            'description': '', \n",
    "                            'application_type': '', \n",
    "                            'data_created': '2020-11-16T10:32:46.003053', \n",
    "                            'project_token': '2ec1d738284daddacca94ca55ee652ec', \n",
    "                            'data_type': [], \n",
    "                            'module_name': [], \n",
    "                            'name': 'icdar2015', \n",
    "                            'consensus': {}}, \n",
    "                'location': {'bu': [], \n",
    "                             'campus': [], \n",
    "                             'plant': [], \n",
    "                             'line': [], \n",
    "                             'station': []}, \n",
    "                'image': {'color_type': 'BGR888', \n",
    "                          'image_resolution': {}}, \n",
    "                'manufacturing': {'product_name': [], \n",
    "                                  'product_sku': [], \n",
    "                                  'part_id': [], \n",
    "                                  'part_number': []}, \n",
    "                'label': {'categories': [{'id': 1, \n",
    "                                          'name': 'text', \n",
    "                                          'supercategory': ''}], \n",
    "                          'number_of_keypoints': None, \n",
    "                          'keypoint_name_list': None, \n",
    "                          'bar_code_type': None, \n",
    "                          'segmentation_type': 'segmentation', \n",
    "                          'label_type': ['polygon', 'text']}, \n",
    "                'filter_options': {}, \n",
    "                'misc': {'job_id': 1206, \n",
    "                         'job_name': 'local_build', \n",
    "                         'creator': 'wade_li', \n",
    "                         'resize': 'none'}}\n",
    "h5[\"meta-dataset\"][0] = json.dumps(meta_dataset)\n",
    "\n",
    "   \n",
    "    \n",
    "for tag in dataset:\n",
    "    counter = 0\n",
    "    annotation_cointer = 0 \n",
    "    print(tag)\n",
    "    if tag == 'train':\n",
    "        img_num = train_num\n",
    "        img_path = 'train_images'\n",
    "        txt_path = 'train_gts'\n",
    "    else:\n",
    "        img_num = validate_num\n",
    "        img_path = 'test_images' \n",
    "        txt_path = 'test_gts'\n",
    "    \n",
    "    grp = h5.create_group(tag) \n",
    "    grp.create_dataset(\"images\", (img_num,), dtype = h5py.special_dtype(vlen=np.dtype('uint8')))\n",
    "    grp.create_dataset(\"meta-info\", (img_num,), dt)\n",
    "    grp.create_dataset(\"meta-label\", (img_num,), dt)\n",
    "    \n",
    "    img_files = os.listdir(img_path)\n",
    "    \n",
    "    for img_file in img_files:\n",
    "        if not 'img_102' in img_file:\n",
    "            continue\n",
    "        print(img_file)\n",
    "        img = cv2.imread(os.path.join(img_path, img_file))\n",
    "        success, encoded_image = cv2.imencode('.jpg', img)\n",
    "        content = encoded_image.tobytes()\n",
    "        h5[tag][\"images\"][counter] = np.fromstring(content, dtype='uint8')\n",
    "        \n",
    "        h5[tag][\"meta-info\"][counter] = json.dumps({\"width\": width,\n",
    "                                                    \"height\": height, \n",
    "                                                    \"color\": \"Binary\", \n",
    "                                                    \"file_name\": img_file, \n",
    "                                                    \"file_url\": ''})\n",
    "        if tag == 'train':\n",
    "            txt_file = os.path.join(txt_path, img_file+'.txt')\n",
    "        else:\n",
    "            txt_file = os.path.join(txt_path, 'gt_'+img_file.strip('.jpg')+'.txt')\n",
    "        meta_label_list = []\n",
    "\n",
    "        f = open(txt_file, 'r', encoding='utf-8')\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            txt = line.encode('utf-8').decode('utf-8-sig')\n",
    "            txt = txt.split(',')\n",
    "            #print(txt)\n",
    "                \n",
    "            x_list = []\n",
    "            y_list = []\n",
    "            seg_list = []           \n",
    "            points = txt[0:8]\n",
    "            point_num = len(points)/2 \n",
    "            contour = []\n",
    "               \n",
    "            for point in range(0, int(point_num)+3, 2):\n",
    "                coordinate = []\n",
    "                x = float(points[point])\n",
    "                y = float(points[point+1])\n",
    "                x_list.append(x)\n",
    "                y_list.append(y)\n",
    "                seg_list.append(x)\n",
    "                seg_list.append(y)\n",
    "                    \n",
    "                coordinate.append(int(x))\n",
    "                coordinate.append(int(y))\n",
    "                contour.append([coordinate])\n",
    "            area = cv2.contourArea(np.array(contour))\n",
    "            max_x = round(max(x_list))\n",
    "            min_x = round(min(x_list))\n",
    "                \n",
    "            max_y = round(max(y_list))\n",
    "            min_y = round(min(y_list))\n",
    "            assert len(seg_list) == 8\n",
    "            for i in seg_list:\n",
    "                assert type(i) == float\n",
    "            print(','.join(txt[8:]).strip('\\n'))\n",
    "            assert ','.join(txt[8:]).strip('\\n') != ''\n",
    "            meta_label_dict = {\"category_id\": 1,\n",
    "                               \"category\": \"text\", \n",
    "                               \"id\": annotation_cointer, \n",
    "                               \"image_id\": counter, \n",
    "                               \"iscrowd\": 0, \n",
    "                               \"segmentation\": [seg_list], \n",
    "                               \"area\": area, \n",
    "                               \"bbox\": [float(min_x), float(min_y), max_x-min_x, max_y-min_y],\n",
    "                               \"text\": ','.join(txt[8:]).strip('\\n')\n",
    "                              }\n",
    "            meta_label_list.append(meta_label_dict)\n",
    "            annotation_cointer += 1\n",
    "            line = f.readline()\n",
    "        h5[tag][\"meta-label\"][counter] = json.dumps(meta_label_list)   \n",
    "        counter += 1\n",
    "        \n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for i in seg_list:\n",
    "    print(type(i))\n",
    "    assert type(i) == float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['images', 'meta-info', 'meta-label']>\n",
      "{\"general\": {\"image_count\": {\"train\": 1, \"validate\": 1, \"test\": 0}, \"labeled_image_count\": 2, \"unlabeled_image_count\": 0, \"image_dataset_format\": \"Binary\", \"description\": \"\", \"application_type\": \"\", \"data_created\": \"2020-11-16T10:32:46.003053\", \"project_token\": \"2ec1d738284daddacca94ca55ee652ec\", \"data_type\": [], \"module_name\": [], \"name\": \"icdar2015\", \"consensus\": {}}, \"location\": {\"bu\": [], \"campus\": [], \"plant\": [], \"line\": [], \"station\": []}, \"image\": {\"color_type\": \"BGR888\", \"image_resolution\": {}}, \"manufacturing\": {\"product_name\": [], \"product_sku\": [], \"part_id\": [], \"part_number\": []}, \"label\": {\"categories\": [{\"id\": 1, \"name\": \"text\", \"supercategory\": \"\"}], \"number_of_keypoints\": null, \"keypoint_name_list\": null, \"bar_code_type\": null, \"segmentation_type\": \"segmentation\", \"label_type\": [\"polygon\", \"text\"]}, \"filter_options\": {}, \"misc\": {\"job_id\": 1206, \"job_name\": \"local_build\", \"creator\": \"wade_li\", \"resize\": \"none\"}}\n",
      "<HDF5 dataset \"meta-label\": shape (1,), type \"|O\">\n",
      "[255 216 255 ... 127 255 217]\n",
      "[{\"category_id\": 1, \"category\": \"text\", \"id\": 0, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[310.0, 504.0, 524.0, 426.0, 555.0, 517.0, 340.0, 594.0]], \"area\": 21776.0, \"bbox\": [310.0, 426.0, 245, 168], \"text\": \"Shop\"}, {\"category_id\": 1, \"category\": \"text\", \"id\": 1, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[594.0, 398.0, 775.0, 336.0, 801.0, 413.0, 620.0, 474.0]], \"area\": 15445.5, \"bbox\": [594.0, 336.0, 207, 138], \"text\": \"Dine\"}, {\"category_id\": 1, \"category\": \"text\", \"id\": 2, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[501.0, 533.0, 777.0, 431.0, 795.0, 503.0, 518.0, 605.0]], \"area\": 21693.0, \"bbox\": [501.0, 431.0, 294, 174], \"text\": \"SMRT\"}]\n",
      "{\"width\": 720, \"height\": 1280, \"color\": \"Binary\", \"file_name\": \"img_102.jpg\", \"file_url\": \"\"}\n",
      "========================================================\n",
      "[255 216 255 ... 127 255 217]\n",
      "[{\"category_id\": 1, \"category\": \"text\", \"id\": 0, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[615.0, 246.0, 698.0, 251.0, 694.0, 281.0, 615.0, 272.0]], \"area\": 2282.0, \"bbox\": [615.0, 246.0, 83, 35], \"text\": \"ST.MARC\"}, {\"category_id\": 1, \"category\": \"text\", \"id\": 1, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[698.0, 252.0, 742.0, 261.0, 740.0, 283.0, 697.0, 278.0]], \"area\": 1054.5, \"bbox\": [697.0, 252.0, 45, 31], \"text\": \"CAFE\"}, {\"category_id\": 1, \"category\": \"text\", \"id\": 2, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[865.0, 223.0, 898.0, 213.0, 901.0, 233.0, 867.0, 243.0]], \"area\": 695.0, \"bbox\": [865.0, 213.0, 36, 30], \"text\": \"###\"}, {\"category_id\": 1, \"category\": \"text\", \"id\": 3, \"image_id\": 0, \"iscrowd\": 0, \"segmentation\": [[902.0, 212.0, 945.0, 198.0, 946.0, 217.0, 903.0, 231.0]], \"area\": 831.0, \"bbox\": [902.0, 198.0, 44, 33], \"text\": \"###\"}]\n",
      "{\"width\": 720, \"height\": 1280, \"color\": \"Binary\", \"file_name\": \"img_102.jpg\", \"file_url\": \"\"}\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('test.h5','r')\n",
    "print(f['validate'].keys())\n",
    "i =0\n",
    "print(f['meta-dataset'][0])\n",
    "print(f['train']['meta-label'])\n",
    "print(f['train']['images'][i])\n",
    "print(f['train']['meta-label'][i])\n",
    "print(f['train']['meta-info'][i])\n",
    "print('========================================================')\n",
    "print(f['validate']['images'][i])\n",
    "print(f['validate']['meta-label'][i])\n",
    "print(f['validate']['meta-info'][i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
